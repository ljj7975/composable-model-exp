{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "import data_loader as data_loaders\n",
    "import model as models\n",
    "import trainer.loss as loss_functions\n",
    "import trainer.metric as metric_functions\n",
    "\n",
    "import utils.util as util\n",
    "from utils import color_print as cp\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model res15/sigmoid_bce_loss/0/kws_res15_narrow_base/0404_214351/model_best.pth\n",
      "class 1 model res15/sigmoid_bce_loss/0/kws_res15_narrow_fine_tune/1/0404_222134/model_best.pth\n",
      "class 2 model res15/sigmoid_bce_loss/0/kws_res15_narrow_fine_tune/2/0404_222230/model_best.pth\n"
     ]
    }
   ],
   "source": [
    "base_model_config = 'config/kws_res15_base.json'\n",
    "fine_model_config = 'config/kws_res15_fine_tune.json'\n",
    "\n",
    "task = \"kws_res15_narrow\"\n",
    "\n",
    "# folder_name = 'test/softmax_bce'\n",
    "folder_name = 'res15/sigmoid_bce_loss/0'\n",
    "most_recent_model = max(os.listdir(folder_name+\"/\"+task+\"_base\"))\n",
    "base_model_cpt = os.path.join(folder_name, task+'_base', most_recent_model, 'model_best.pth')\n",
    "print('base_model', base_model_cpt)\n",
    "\n",
    "most_recent_model = max(os.listdir(folder_name+\"/\"+task+\"_fine_tune/1/\"))\n",
    "model_1_cpt = os.path.join(folder_name, task+'_fine_tune/1/', most_recent_model, 'model_best.pth')\n",
    "print('class 1 model', model_1_cpt)\n",
    "\n",
    "most_recent_model = max(os.listdir(folder_name+\"/{}_fine_tune/2/\".format(task)))\n",
    "model_2_cpt = os.path.join(folder_name, task+'_fine_tune/2/', most_recent_model, 'model_best.pth')\n",
    "print('class 2 model', model_2_cpt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_all_model = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'kws_res15_narrow_base',\n",
       " 'n_gpu': 1,\n",
       " 'n_class': 30,\n",
       " 'model': {'type': 'ResNarrowNet',\n",
       "  'args': {'num_classes': 30,\n",
       "   'n_layers': 13,\n",
       "   'n_feature_maps': 19,\n",
       "   'use_dilation': True}},\n",
       " 'data_loader': {'type': 'GoogleKeywordDataLoader',\n",
       "  'args': {'data_dir': '/media/brandon/SSD/data/speech_dataset',\n",
       "   'batch_size': 128,\n",
       "   'shuffle': True,\n",
       "   'validation_split': 0.1,\n",
       "   'num_workers': 2,\n",
       "   'seed': 126}},\n",
       " 'optimizer': {'type': 'SGD',\n",
       "  'args': {'lr': 0.1, 'weight_decay': 0.0001, 'momentum': 0.9}},\n",
       " 'loss': 'sigmoid_bce_loss',\n",
       " 'metrics': ['pred_acc'],\n",
       " 'lr_scheduler': {'type': 'MultiStepLR',\n",
       "  'args': {'milestones': [10, 20], 'gamma': 0.1}},\n",
       " 'trainer': {'epochs': 30,\n",
       "  'save_dir': 'saved/',\n",
       "  'save_period': 1,\n",
       "  'verbosity': 2,\n",
       "  'monitor': 'min val_loss',\n",
       "  'early_stop': 10,\n",
       "  'tensorboardX': True,\n",
       "  'log_dir': 'saved/runs'}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_config = torch.load(base_model_cpt)['config']\n",
    "if \"media\" not in base_config['data_loader']['args']['data_dir']:\n",
    "    base_config['data_loader']['args']['data_dir'] = \"/media/brandon/SSD\" + base_config['data_loader']['args']['data_dir']\n",
    "base_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base = util.get_instance(models, 'model', base_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_base = torch.load(base_model_cpt)\n",
    "state_dict_base = checkpoint_base['state_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< Dataset Summary >\n",
      "\tseed\t: 0\n",
      "\t bed \t: 0  ( 3 )\n",
      "\t bird \t: 1  ( 3 )\n",
      "\t cat \t: 2  ( 3 )\n",
      "\t dog \t: 3  ( 3 )\n",
      "\t down \t: 4  ( 3 )\n",
      "\t eight \t: 5  ( 3 )\n",
      "\t five \t: 6  ( 3 )\n",
      "\t four \t: 7  ( 3 )\n",
      "\t go \t: 8  ( 3 )\n",
      "\t happy \t: 9  ( 3 )\n",
      "\t house \t: 10  ( 3 )\n",
      "\t left \t: 11  ( 3 )\n",
      "\t marvin \t: 12  ( 3 )\n",
      "\t nine \t: 13  ( 3 )\n",
      "\t no \t: 14  ( 3 )\n",
      "\t off \t: 15  ( 3 )\n",
      "\t on \t: 16  ( 3 )\n",
      "\t one \t: 17  ( 3 )\n",
      "\t right \t: 18  ( 3 )\n",
      "\t seven \t: 19  ( 3 )\n",
      "\t sheila \t: 20  ( 3 )\n",
      "\t six \t: 21  ( 3 )\n",
      "\t stop \t: 22  ( 3 )\n",
      "\t three \t: 23  ( 3 )\n",
      "\t tree \t: 24  ( 3 )\n",
      "\t two \t: 25  ( 3 )\n",
      "\t up \t: 26  ( 3 )\n",
      "\t wow \t: 27  ( 3 )\n",
      "\t yes \t: 28  ( 3 )\n",
      "\t zero \t: 29  ( 3 )\n",
      "total data size :  90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 1/1 [00:00<00:00,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\n",
      "[ PROGRESS ] ::  TEST RESULTS\n",
      "\tloss : 0.04041166603565216\n",
      "\tpred_acc : 0.9333333333333333\n",
      "\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if eval_all_model:\n",
    "    model_base.load_state_dict(state_dict_base)\n",
    "    model_base.eval()\n",
    "    \n",
    "    base_target_class = list(np.arange(base_config['n_class']))\n",
    "    base_size_per_class = 3\n",
    "\n",
    "    base_data_loader = getattr(data_loaders, base_config['data_loader']['type'])(\n",
    "        base_config['data_loader']['args']['data_dir'],\n",
    "        batch_size=512,\n",
    "        shuffle=False,\n",
    "        validation_split=0.0,\n",
    "        training=False,\n",
    "        num_workers=2,\n",
    "        size_per_class=base_size_per_class,\n",
    "        target_class=base_target_class,\n",
    "        unknown=True\n",
    "    )\n",
    "    \n",
    "    base_loss_fn = getattr(loss_functions, base_config['loss'])\n",
    "\n",
    "    base_config['metrics'] = [\"pred_acc\"]\n",
    "\n",
    "    base_metrics = [getattr(metric_functions, met) for met in base_config['metrics']]\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    total_metrics = torch.zeros(len(base_metrics))\n",
    "\n",
    "    with torch.no_grad():\n",
    "            for i, (data, target) in enumerate(tqdm(base_data_loader)):\n",
    "                one_hot_target = torch.eye(len(base_target_class))[target]\n",
    "\n",
    "                if \"kws\" not in task:\n",
    "                    plt.figure(figsize=[15,15])\n",
    "\n",
    "                    for index, image in enumerate(data):\n",
    "                        plt.subplot(len(data)/ size_per_class_base, size_per_class_base, index+1)\n",
    "                        plt.imshow(np.reshape(torch.squeeze(image), [28,28]), cmap='gray')\n",
    "                        plt.axis('off')\n",
    "                        plt.title(target[index].item())\n",
    "\n",
    "                output = model_base(data)\n",
    "\n",
    "                # computing loss, metrics on test set\n",
    "                loss = base_loss_fn(output, one_hot_target)\n",
    "#                 loss = base_loss_fn(output, target)\n",
    "                batch_size = data.shape[0]\n",
    "                total_loss += loss.item() * batch_size\n",
    "                for i, metric in enumerate(base_metrics):\n",
    "                    total_metrics[i] += metric(output, target) * batch_size\n",
    "\n",
    "    n_samples = len(base_data_loader.sampler)\n",
    "    log = {'loss': total_loss / n_samples}\n",
    "    log.update({met.__name__ : total_metrics[i].item() / n_samples for i, met in enumerate(base_metrics)})\n",
    "\n",
    "    test_result_str = 'TEST RESULTS\\n'\n",
    "    for key, val in log.items():\n",
    "        test_result_str += ('\\t' + str(key) + ' : ' + str(val) + '\\n')\n",
    "\n",
    "    cp.print_progress(test_result_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_fn = getattr(loss_functions, base_config['loss'])\n",
    "\n",
    "# base_config['metrics'] = [\"pred_acc\"]\n",
    "\n",
    "# metrics = [getattr(metric_functions, met) for met in base_config['metrics']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss = 0.0\n",
    "total_metrics = torch.zeros(len(metrics))\n",
    "\n",
    "with torch.no_grad():\n",
    "        for i, (data, target) in enumerate(tqdm(data_loader)):\n",
    "            one_hot_target = torch.eye(len(target_class_base))[target]\n",
    "            \n",
    "            plt.figure(figsize=[15,15])\n",
    "\n",
    "            for index, image in enumerate(data):\n",
    "                plt.subplot(len(data)/ size_per_class_base, size_per_class_base, index+1)\n",
    "                plt.imshow(np.reshape(torch.squeeze(image), [28,28]), cmap='gray')\n",
    "                plt.axis('off')\n",
    "                plt.title(target[index].item())\n",
    "\n",
    "            output = model_base(data)\n",
    "            \n",
    "            # computing loss, metrics on test set\n",
    "#             loss = loss_fn(output, one_hot_target)\n",
    "            loss = loss_fn(output, target)\n",
    "            batch_size = data.shape[0]\n",
    "            total_loss += loss.item() * batch_size\n",
    "            for i, metric in enumerate(metrics):\n",
    "                total_metrics[i] += metric(output, target) * batch_size\n",
    "\n",
    "n_samples = len(data_loader.sampler)\n",
    "log = {'loss': total_loss / n_samples}\n",
    "log.update({met.__name__ : total_metrics[i].item() / n_samples for i, met in enumerate(metrics)})\n",
    "\n",
    "test_result_str = 'TEST RESULTS\\n'\n",
    "for key, val in log.items():\n",
    "    test_result_str += ('\\t' + str(key) + ' : ' + str(val) + '\\n')\n",
    "\n",
    "cp.print_progress(test_result_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fine tuned model - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'mnist_fine_tune',\n",
       " 'n_gpu': 1,\n",
       " 'model': {'type': 'LeNet', 'args': {}},\n",
       " 'data_loader': {'type': 'MnistDataLoader',\n",
       "  'args': {'data_dir': '/media/brandon/SSD/data/mnist',\n",
       "   'batch_size': 128,\n",
       "   'shuffle': True,\n",
       "   'validation_split': 0.1,\n",
       "   'num_workers': 2,\n",
       "   'target_class': [1],\n",
       "   'unknown': True}},\n",
       " 'optimizer': {'type': 'Adam',\n",
       "  'args': {'lr': 0.001, 'weight_decay': 0, 'amsgrad': True}},\n",
       " 'loss': 'bce_logits_loss',\n",
       " 'metrics': ['pred_acc'],\n",
       " 'lr_scheduler': {'type': 'StepLR', 'args': {'step_size': 50, 'gamma': 0.1}},\n",
       " 'trainer': {'epochs': 10,\n",
       "  'save_dir': 'saved/',\n",
       "  'save_period': 1,\n",
       "  'verbosity': 2,\n",
       "  'monitor': 'min val_loss',\n",
       "  'early_stop': 10,\n",
       "  'tensorboardX': True,\n",
       "  'log_dir': 'saved/runs'},\n",
       " 'target_class': [1]}"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_1 = torch.load(model_1_cpt)['config']\n",
    "config_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet(\n",
       "  (conv1): Conv2d(1, 5, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(5, 5, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2_drop): Dropout2d(p=0.5)\n",
       "  (fc1): Linear(in_features=80, out_features=50, bias=True)\n",
       "  (fc2): Linear(in_features=50, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1 = util.get_instance(models, 'model', config_1)\n",
    "layer_id = model_1.swap_fc(len(config_1['target_class']) + 1)\n",
    "model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_1 = torch.load(model_1_cpt)\n",
    "state_dict_1 = checkpoint_1['state_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_1.load_state_dict(state_dict_1)\n",
    "# model_1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size_per_class_1 = 2\n",
    "# print(\"target class :\", config_1['target_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # data_loader = getattr(data_loaders, config_1['data_loader']['type'])(\n",
    "# #     config_1['data_loader']['args']['data_dir'],\n",
    "# #     batch_size=512,\n",
    "# #     shuffle=False,\n",
    "# #     validation_split=0.0,\n",
    "# #     training=False,\n",
    "# #     num_workers=2,\n",
    "# #     size_per_class=size_per_class_1,\n",
    "# #     target_class=config_1['target_class'],\n",
    "# #     unknown=True\n",
    "# # )\n",
    "\n",
    "# data_loader = getattr(data_loaders, config_1['data_loader']['type'])(\n",
    "#     config_1['data_loader']['args']['data_dir'],\n",
    "#     batch_size=512,\n",
    "#     shuffle=False,\n",
    "#     validation_split=0.0,\n",
    "#     training=False,\n",
    "#     num_workers=2,\n",
    "#     size_per_class=size_per_class_1,\n",
    "#     target_class=[1,2],\n",
    "#     unknown=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_loss = 0.0\n",
    "# total_metrics = torch.zeros(len(metrics))\n",
    "\n",
    "# with torch.no_grad():\n",
    "#         for i, (data, target) in enumerate(tqdm(data_loader)):\n",
    "#             one_hot_target = torch.eye(2)[target]\n",
    "            \n",
    "#             plt.figure(figsize=[5,5])\n",
    "\n",
    "#             for index, image in enumerate(data):\n",
    "#                 plt.subplot(len(data)/ size_per_class_1, size_per_class_1, index+1)\n",
    "#                 plt.imshow(np.reshape(torch.squeeze(image), [28,28]), cmap='gray')\n",
    "#                 plt.axis('off')\n",
    "#                 plt.title(target[index].item())\n",
    "\n",
    "#             output = model_1(data)\n",
    "            \n",
    "#             # computing loss, metrics on test set\n",
    "# #             loss = loss_fn(output, one_hot_target)\n",
    "#             loss = loss_fn(output, target)\n",
    "#             batch_size = data.shape[0]\n",
    "#             total_loss += loss.item() * batch_size\n",
    "#             for i, metric in enumerate(metrics):\n",
    "#                 total_metrics[i] += metric(output, target) * batch_size\n",
    "\n",
    "# n_samples = len(data_loader.sampler)\n",
    "# log = {'loss': total_loss / n_samples}\n",
    "# log.update({met.__name__ : total_metrics[i].item() / n_samples for i, met in enumerate(metrics)})\n",
    "\n",
    "# test_result_str = 'TEST RESULTS\\n'\n",
    "# for key, val in log.items():\n",
    "#     test_result_str += ('\\t' + str(key) + ' : ' + str(val) + '\\n')\n",
    "\n",
    "# cp.print_progress(test_result_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fine tuned model - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'mnist_fine_tune',\n",
       " 'n_gpu': 1,\n",
       " 'model': {'type': 'LeNet', 'args': {}},\n",
       " 'data_loader': {'type': 'MnistDataLoader',\n",
       "  'args': {'data_dir': '/media/brandon/SSD/data/mnist',\n",
       "   'batch_size': 128,\n",
       "   'shuffle': True,\n",
       "   'validation_split': 0.1,\n",
       "   'num_workers': 2,\n",
       "   'target_class': [2],\n",
       "   'unknown': True}},\n",
       " 'optimizer': {'type': 'Adam',\n",
       "  'args': {'lr': 0.001, 'weight_decay': 0, 'amsgrad': True}},\n",
       " 'loss': 'bce_logits_loss',\n",
       " 'metrics': ['pred_acc'],\n",
       " 'lr_scheduler': {'type': 'StepLR', 'args': {'step_size': 50, 'gamma': 0.1}},\n",
       " 'trainer': {'epochs': 10,\n",
       "  'save_dir': 'saved/',\n",
       "  'save_period': 1,\n",
       "  'verbosity': 2,\n",
       "  'monitor': 'min val_loss',\n",
       "  'early_stop': 10,\n",
       "  'tensorboardX': True,\n",
       "  'log_dir': 'saved/runs'},\n",
       " 'target_class': [2]}"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_2 = torch.load(model_2_cpt)['config']\n",
    "config_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet(\n",
       "  (conv1): Conv2d(1, 5, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(5, 5, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2_drop): Dropout2d(p=0.5)\n",
       "  (fc1): Linear(in_features=80, out_features=50, bias=True)\n",
       "  (fc2): Linear(in_features=50, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2 = util.get_instance(models, 'model', config_2)\n",
    "layer_id = model_2.swap_fc(len(config_2['target_class']) + 1)\n",
    "model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_2 = torch.load(model_2_cpt)\n",
    "state_dict_2 = checkpoint_2['state_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_2.load_state_dict(state_dict_2)\n",
    "# model_2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size_per_class_2 = 2\n",
    "# print(\"target class :\", config_2['target_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_loader = getattr(data_loaders, config_2['data_loader']['type'])(\n",
    "#     config_2['data_loader']['args']['data_dir'],\n",
    "#     batch_size=512,\n",
    "#     shuffle=False,\n",
    "#     validation_split=0.0,\n",
    "#     training=False,\n",
    "#     num_workers=2,\n",
    "#     size_per_class=size_per_class_2,\n",
    "#     target_class=[2,1],\n",
    "#     unknown=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_loss = 0.0\n",
    "# total_metrics = torch.zeros(len(metrics))\n",
    "\n",
    "# with torch.no_grad():\n",
    "#         for i, (data, target) in enumerate(tqdm(data_loader)):\n",
    "#             one_hot_target = torch.eye(2)[target]\n",
    "            \n",
    "#             plt.figure(figsize=[5,5])\n",
    "\n",
    "#             for index, image in enumerate(data):\n",
    "#                 plt.subplot(len(data)/ size_per_class_2, size_per_class_2, index+1)\n",
    "#                 plt.imshow(np.reshape(torch.squeeze(image), [28,28]), cmap='gray')\n",
    "#                 plt.axis('off')\n",
    "#                 plt.title(target[index].item())\n",
    "\n",
    "#             output = model_2(data)\n",
    "            \n",
    "#             # computing loss, metrics on test set\n",
    "# #             loss = loss_fn(output, one_hot_target)\n",
    "#             loss = loss_fn(output, target)\n",
    "#             batch_size = data.shape[0]\n",
    "#             total_loss += loss.item() * batch_size\n",
    "#             for i, metric in enumerate(metrics):\n",
    "#                 total_metrics[i] += metric(output, target) * batch_size\n",
    "\n",
    "# n_samples = len(data_loader.sampler)\n",
    "# log = {'loss': total_loss / n_samples}\n",
    "# log.update({met.__name__ : total_metrics[i].item() / n_samples for i, met in enumerate(metrics)})\n",
    "\n",
    "# test_result_str = 'TEST RESULTS\\n'\n",
    "# for key, val in log.items():\n",
    "#     test_result_str += ('\\t' + str(key) + ' : ' + str(val) + '\\n')\n",
    "\n",
    "# cp.print_progress(test_result_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# combined model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_class = [1, 2]\n",
    "base_config = torch.load(base_model_cpt)['config']\n",
    "model = util.get_instance(models, 'model', base_config)\n",
    "checkpoint_base = torch.load(base_model_cpt)\n",
    "state_dict_base = checkpoint_base['state_dict']\n",
    "\n",
    "model.load_state_dict(state_dict_base)\n",
    "\n",
    "\n",
    "# print('base')\n",
    "# for k,v in model_base.named_parameters():\n",
    "#     print(k, torch.mean(v).item())\n",
    "\n",
    "# print('old')\n",
    "# for k,v in model_1.named_parameters():\n",
    "#     print(k, torch.mean(v).item())\n",
    "    \n",
    "# print('old2')\n",
    "# for k,v in model_2.named_parameters():\n",
    "#     print(k, torch.mean(v).item())\n",
    "    \n",
    "# print('combined')\n",
    "# for k,v in model.named_parameters():\n",
    "#     print(k, torch.mean(v).item())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_1 = state_dict_1[\"fc2.weight\"][0]\n",
    "bias_1 = state_dict_1[\"fc2.bias\"][0]\n",
    "\n",
    "weight_2 = state_dict_2[\"fc2.weight\"][0]\n",
    "bias_2 = state_dict_2[\"fc2.bias\"][0]\n",
    "\n",
    "weight_list = [weight_1, weight_2]\n",
    "bias_list = [bias_1, bias_2]\n",
    "\n",
    "weight = torch.stack(weight_list)\n",
    "bias = torch.stack(bias_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet(\n",
       "  (conv1): Conv2d(1, 5, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(5, 5, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2_drop): Dropout2d(p=0.5)\n",
       "  (fc1): Linear(in_features=80, out_features=50, bias=True)\n",
       "  (fc2): Linear(in_features=50, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_id = model.swap_fc(len(target_class))\n",
    "model.fc2.weight = torch.nn.Parameter(weight)\n",
    "model.fc2.bias = torch.nn.Parameter(bias)\n",
    "\n",
    "model.to(torch.device('cpu'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = getattr(loss_functions, base_config['loss'])\n",
    "\n",
    "base_config['metrics'] = [\"pred_acc\"]\n",
    "\n",
    "metrics = [getattr(metric_functions, met) for met in base_config['metrics']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size_per_class = 1000\n",
    "# data_loader = getattr(data_loaders, config_1['data_loader']['type'])(\n",
    "#     config_1['data_loader']['args']['data_dir'],\n",
    "#     batch_size=512,\n",
    "#     shuffle=False,\n",
    "#     validation_split=0.0,\n",
    "#     training=False,\n",
    "#     num_workers=2,\n",
    "#     size_per_class=size_per_class,\n",
    "#     target_class=target_class,\n",
    "#     unknown=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test/identity_softmax_bce\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brandon/Documents/courses/CS886/composable-model-exp/model/le_net.py:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : [0.40989843010902405, 0.5901015996932983]\n",
      "0 : [0.09660104662179947, 0.9033989906311035]\n",
      "0 : [0.17841428518295288, 0.8215857148170471]\n",
      "0 : [0.4459337890148163, 0.5540662407875061]\n",
      "0 : [0.03756008297204971, 0.9624398946762085]\n",
      "0 : [0.19705691933631897, 0.8029430508613586]\n",
      "0 : [0.44178715348243713, 0.5582128167152405]\n",
      "0 : [0.04545839875936508, 0.9545416235923767]\n",
      "0 : [0.09829176217317581, 0.9017082452774048]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 1/4 [00:00<00:01,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : [0.013788566924631596, 0.9862114191055298]\n",
      "0 : [0.32151496410369873, 0.6784849762916565]\n",
      "0 : [0.27290472388267517, 0.7270951867103577]\n",
      "0 : [0.17582440376281738, 0.8241756558418274]\n",
      "0 : [0.4444516897201538, 0.5555483102798462]\n",
      "0 : [0.4328670799732208, 0.5671328902244568]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 2/4 [00:00<00:00,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : [0.38003700971603394, 0.6199629902839661]\n",
      "0 : [0.4565279185771942, 0.5434721112251282]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "softmax\n",
      "\u001b[92m\n",
      "[ PROGRESS ] ::  TEST RESULTS\n",
      "\tloss : 0.5243982200622559\n",
      "\tpred_acc : 0.9915\n",
      "\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "total_loss = 0.0\n",
    "total_metrics = torch.zeros(len(metrics))\n",
    "\n",
    "# plt.figure(figsize=[15,15])\n",
    "counter = 0\n",
    "print(folder_name)\n",
    "\n",
    "with torch.no_grad():\n",
    "        for i, (data, target) in enumerate(tqdm(data_loader)):        \n",
    "            one_hot_target = torch.eye(2)[target]\n",
    "            \n",
    "            output = model(data)\n",
    "    \n",
    "            for index, image in enumerate(data):\n",
    "                result_1 = model_1(torch.unsqueeze(image, dim=0)).tolist()[0][0]\n",
    "                result_2 = model_2(torch.unsqueeze(image, dim=0)).tolist()[0][0]\n",
    "                \n",
    "                arr = [result_1, result_2]\n",
    "                result = model(torch.unsqueeze(image, dim=0)).tolist()[0]\n",
    "#                 print(index)\n",
    "#                 print('softmax', nn.Softmax()(model(torch.unsqueeze(image, dim=0))))\n",
    "#                 print('sigmoid', nn.Sigmoid()(model(torch.unsqueeze(image, dim=0))))\n",
    "#                 break\n",
    "                \n",
    "                if target[index].item() != np.argmax(np.array(result)):\n",
    "#                     plt.subplot(20, 1, counter+1)\n",
    "#                     counter += 1\n",
    "#                     plt.imshow(np.reshape(torch.squeeze(image), [28,28]), cmap='gray')\n",
    "#                     plt.axis('off')\n",
    "#                     summary = str(target[index].item()) + \" : \" + str( arr ) + \" ->\" + str(result)\n",
    "#                     plt.title(str(target[index].item()) + \" : \" + str( arr ))\n",
    "\n",
    "                    print(str(target[index].item()) + \" : \" + str( result ))\n",
    "#                     print('\\t', nn.Softmax()(model(torch.unsqueeze(image, dim=0))))\n",
    "                \n",
    "            \n",
    "            # computing loss, metrics on test set\n",
    "            loss = loss_fn(output, one_hot_target)\n",
    "#             print('target', target.shape)\n",
    "#             print('output', output.shape)\n",
    "#             loss = loss_fn(output, target)\n",
    "            batch_size = data.shape[0]\n",
    "            total_loss += loss.item() * batch_size\n",
    "            for i, metric in enumerate(metrics):\n",
    "                total_metrics[i] += metric(output, target) * batch_size\n",
    "\n",
    "n_samples = len(data_loader.sampler)\n",
    "log = {'loss': total_loss / n_samples}\n",
    "log.update({met.__name__ : total_metrics[i].item() / n_samples for i, met in enumerate(metrics)})\n",
    "\n",
    "test_result_str = 'TEST RESULTS\\n'\n",
    "for key, val in log.items():\n",
    "    test_result_str += ('\\t' + str(key) + ' : ' + str(val) + '\\n')\n",
    "\n",
    "cp.print_progress(test_result_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
